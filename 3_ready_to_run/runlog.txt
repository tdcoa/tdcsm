

========================================
TDCOA STARTED                 
----------------------------------------
time:                         2020-06-30 15:48:29.405734
app root:                     C:\Users\KT250034\PROJECTS\Customer_Success\Github\develop_branch\tdcsm
config file:                  C:\Users\KT250034\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\config.yaml
source systems file:          C:\Users\KT250034\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\source_systems.yaml
secrets file:                 C:\Users\KT250034\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\secrets.yaml
tdcoa version:                0.3.9.6.2


========================================
RELOAD_CONFIG STARTED         
----------------------------------------
time:                         2020-06-30 15:48:29.406730
tdcoa version:                0.3.9.6.2
checking core config files    
    performing substitution:  secrets
     {td_quicklook}:          K******4
     {td_password}:           W*********3
    performing substitution:  config:substitutions
    performing substitution:  config:folders
     {download}:              1_download
    performing substitution:  config:settings
    performing substitution:  config:transcend
loading dictionary:           substitutions
    performing substitution:  secrets
     {td_quicklook}:          K******4
     {td_password}:           W*********3
     {custabc_username}:      c**********e
     {custabc_password}:      T******************d
    performing substitution:  systems:substitutions
loading dictionary:           transcend
loading dictionary:           folders
loading dictionary:           settings
unbuffering log to "run" folder
githost:                      https://raw.githubusercontent.com/tdcoa/sql/master/
downloading "filesets.yaml" from github
  requesting url:             https://raw.githubusercontent.com/tdcoa/sql/master/filesets/filesets.yaml
saving filesets.yaml:         C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\./1_download/filesets.yaml
filesets.yaml saved           
loading dictionary:           filesets (active only)
loading system dictionaries (active only)
  active dictionary:          Transcend_Source
  INACTIVE dictionary:        Customer_System_Example
done!                         
time:                         2020-06-30 15:48:34.342326


========================================
DOWNLOAD_FILES STARTED        
----------------------------------------
time:                         2020-06-30 15:48:43.193657
githost:                      https://raw.githubusercontent.com/tdcoa/sql/master/
downloading "motd.html" from github
  requesting url:             https://raw.githubusercontent.com/tdcoa/sql/master/motd.html
purge all subfolders:         C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\1_download
 recursively deleting:        C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\1_download\demo
  active dictionary:          Transcend_Source

INTERROGATING SYSTEM:        Transcend_Source
  active dictionary:          demo
  found fileset:              demo
  cross-referencing with filesets.yaml...
  active dictionary:          demo
  FILE SET FOUND:             demo [5]
   --------------------------------------------------
   file01                     
   downloading file:          demo/dates.csv
    https://raw.githubusercontent.com/tdcoa/sql/master/filesets/demo/dates.csv
    saving file to:           C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\1_download\demo\dates.csv
   --------------------------------------------------
   file02                     
   downloading file:          demo/dbcinfo.coa.sql
    https://raw.githubusercontent.com/tdcoa/sql/master/filesets/demo/dbcinfo.coa.sql
    saving file to:           C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\1_download\demo\dbcinfo.coa.sql
   --------------------------------------------------
   file03                     
   downloading file:          demo/today.sql
    https://raw.githubusercontent.com/tdcoa/sql/master/filesets/demo/today.sql
    saving file to:           C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\1_download\demo\today.sql
   --------------------------------------------------
   file04                     
   downloading file:          demo/alldates.py
    https://raw.githubusercontent.com/tdcoa/sql/master/filesets/demo/alldates.py
    saving file to:           C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\1_download\demo\alldates.py
   --------------------------------------------------
   file05                     
   downloading file:          demo/AgeReport.pptx
    https://raw.githubusercontent.com/tdcoa/sql/master/filesets/demo/AgeReport.pptx
    saving file to:           C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\1_download\demo\AgeReport.pptx
   --------------------------------------------------


done!                        
time:                         2020-06-30 15:48:52.237983


========================================
COPY_DOWNLOAD_TO_SQL STARTED  
----------------------------------------
copy files from download folder (by fileset) to sql folder (by system)
time:                         2020-06-30 15:48:52.246983
purge all subfolders:         C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\2_sql_store
 recursively deleting:        C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\2_sql_store\Transcend_Source
processing system:            Transcend_Source
  active dictionary           
processing fileset:           demo
  active dictionary           

done!                        
time:                         2020-06-30 15:48:52.413084


========================================
PREPARE_SQL STARTED           
----------------------------------------
time:                         2020-06-30 15:49:03.521558
 sql folder:                  2_sql_store
 run folder:                  3_ready_to_run
applying file override        
 override folder:             C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\0_override
 target_folder:               C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\2_sql_store

processing files found in override root
these files replace any matching filename, regardless of subfolder location

perform override file copy:  

apply override complete!     
empty run folder entirely     
purge all subfolders:         C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run
 recursively deleting:        C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source

------------------------------
SYSTEM FOLDER FOUND:          Transcend_Source
  active dictionary           
FILESET FOLDER FOUND:         demo
  folder MATCHES a defined fileset name:demo
  active dictionary           
  active dictionary           
  and fileset record is active, continuing...
  creating system folder:     C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source
  creating fileset folder:    C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source\demo
 recursive_copyfolder source: C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\2_sql_store\Transcend_Source\demo
    file copied:              C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source\demo\AgeReport.pptx
    file copied:              C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source\demo\alldates.py
    file copied:              C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source\demo\dates.csv
    file copied:              C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source\demo\dbcinfo.coa.sql
    file copied:              C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source\demo\today.sql

  PROCESSING COA.SQL FILE:   dbcinfo.coa.sql
  characters in file:         1690
  active dictionary:          system-fileset overrides
    performing substitution:  system-fileset overrides (highest priority)
  active dictionary:          system defaults
    performing substitution:  system defaults
     {siteid}:                TDCLOUD14TD03
  always use dictionary       
    performing substitution:  overall app defaults (config.substitutions)
     {account}:               Demo Customer
    performing substitution:  overall transcend database defaults (db_coa and db_region)
     {db_coa}:                adlste_coa
    performing substitution:  file substitutions
  active dictionary:          fileset defaults
    performing substitution:  fileset defaults (lowest priority)
     {fileset_version}:       1.15
     {birthday}:              1974-12-17
  sql statements in file:     12
  SQL 1:                      /*{{save:dbcinfo.csv}}*/ /*{{load:adlste_coa_stg.s...
  parsing for special sql commands
   special command found:     save = dbcinfo.csv
   special command found:     load = adlste_coa_stg.stg_dat_dbcinfo
   special command found:     call = adlste_coa.sp_dat_dbcinfo('1.15')
  processing special commands 
  SQL 2:                      create volatile table valid_dates (cal_date date ,...
  parsing for special sql commands
  processing special commands 
  SQL 3:                      /* first method to load .csv into database tables:...
  parsing for special sql commands
  processing special commands 
  SQL 4:                      /*{{loop:dates.csv}}*/ insert into valid_dates val...
  parsing for special sql commands
   special command found:     loop = dates.csv
   loop found in keys_to_skip, skipping...
  processing special commands 
   loop sql once per row in .csv, with substitutions
   file found!                
   rows in file:              6
   perform csv file substitutions (find: {column_name}, replace: row value)
   sql generated from row data:character length = 83
   sql generated from row data:character length = 87
   sql generated from row data:character length = 83
   sql generated from row data:character length = 89
   sql generated from row data:character length = 87
   sql generated from row data:character length = 80
  SQL 5:                      /* second method to load .csv into database tables...
  parsing for special sql commands
  processing special commands 
  SQL 6:                      /*{{temp:dates.csv}}*/ delete from valid_dates ;...
  parsing for special sql commands
   special command found:     temp = dates.csv
   temp found in keys_to_skip, skipping...
  processing special commands 
   create temp (volatile) table from .csv
   csv file found:            dates.csv
    transcribing sql:         dates.csv
    open csv:                 dates.csv
    rows in file:             6
    rows per chunk:           100
building chunk 1 containing rows 0 thru 6
sql built for:                dates.csv
  SQL 7:                      insert into valid_dates Select cal_date, item from...
  parsing for special sql commands
  processing special commands 
  SQL 8:                      /* birthday is substituted from either the config....
  parsing for special sql commands
  processing special commands 
  SQL 9:                      insert into valid_dates values( cast('1974-12-17' ...
  parsing for special sql commands
  processing special commands 
  SQL 10:                     /* export birthday for value:replacement later */ ...
  parsing for special sql commands
   special command found:     save = birthday.csv
  processing special commands 
  SQL 11:                     /* simply plop the below sql file right here: */ /...
  parsing for special sql commands
   special command found:     file = today.sql
   file found in keys_to_skip, skipping...
  processing special commands 
   replace variable with a local sql file
   specified file found:      today.sql
  SQL 12:                     /* save the resultset output to the listed .csv */...
  parsing for special sql commands
   special command found:     save = alldates.csv
   special command found:     vis = alldates.csv
   special command found:     pptx = AgeReport.pptx
  processing special commands 
  writing out final sql       
done!                         
time:                         2020-06-30 15:49:03.781310


========================================
EXECUTE_RUN STARTED           
----------------------------------------
time:                         2020-06-30 15:49:07.438111
save location of last-run output folder to hidden file
last-run output:              C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\4_output\2020-06-30_154907


========================================
SYSTEM:  TRANSCEND_SOURCE   FILESET:  DEMO
----------------------------------------
work (sql) path:              C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source\demo
output path:                  C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\4_output\2020-06-30_154907\Transcend_Source\demo
found prepared sql file:      dbcinfo.coa.sql
all sql files alpha-sorted for exeuction consistency
sql files found:              1
output folder:                C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\4_output\2020-06-30_154907\Transcend_Source\demo
creating upload manifest file 
OPEN_CONNECTION started:      2020-06-30 15:49:07.459111
  connection type:            sqlalchemy
  host:                       tdprdcop3.td.teradata.com
  logmech:                    ldap
  username:                   K******4
  password:                   W*********3
connecting...                 
connected!:                   2020-06-30 15:49:07.830816

OPENING SQL FILE:            dbcinfo.coa.sql

---- SQL #1                  
  parsing for special sql commands
   special command found:     save = dbcinfo.csv
   save found in keys_to_skip, skipping...
   special command found:     load = adlste_coa_stg.stg_dat_dbcinfo
   load found in keys_to_skip, skipping...
   special command found:     call = adlste_coa.sp_dat_dbcinfo('1.15')
   call found in keys_to_skip, skipping...
connection type:              sqlalchemy
sql, first 100 characters:
  Select  'Demo Customer' as Account_Name ,'TDCLOUD14TD03' as Site_ID ,d.InfoKey ,d.InfoData from d...
sql submitted:                2020-06-30 15:49:07.867329
sql completed:                2020-06-30 15:49:18.709976
record count:                 3
CSV save location:            C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source\demo\dbcinfo.csv
saving file...                
file saved!                   
file marked for loading to Transcend, adding to upload-manifest.json
Manifest updated:             
 {"file": "dbcinfo.csv",
  "table": "adlste_coa_stg.stg_dat_dbcinfo",
  "call": "adlste_coa.sp_dat_dbcinfo('1.15')"}

---- SQL #2                  
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  create volatile table valid_dates (cal_date date ,item  varchar(64)) no primary index on commit pr...
sql submitted:                2020-06-30 15:49:18.776541
sql completed:                2020-06-30 15:49:21.148595
record count:                 0

---- SQL #3                  
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  /* first method to load .csv into database tables: loop    which opens a .csv file and loops the s...
sql submitted:                2020-06-30 15:49:21.164599
sql completed:                2020-06-30 15:49:23.544241
record count:                 0

---- SQL #4                  
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  /*  csv row 1 out of 6  */ insert into valid_dates values('2020/01/01', 'Decade')...
sql submitted:                2020-06-30 15:49:23.560238
sql completed:                2020-06-30 15:49:26.165990
record count:                 0

---- SQL #5                  
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  /*  csv row 2 out of 6  */ insert into valid_dates values('2000/01/01', 'Millennium')...
sql submitted:                2020-06-30 15:49:26.170992
sql completed:                2020-06-30 15:49:29.222764
record count:                 0

---- SQL #6                  
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  /*  csv row 3 out of 6  */ insert into valid_dates values('2007/05/29', 'iPhone')...
sql submitted:                2020-06-30 15:49:29.233756
sql completed:                2020-06-30 15:49:31.849615
record count:                 0

---- SQL #7                  
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  /*  csv row 4 out of 6  */ insert into valid_dates values('1941/12/07', 'Pearl Harbor')...
sql submitted:                2020-06-30 15:49:31.862658
sql completed:                2020-06-30 15:49:34.278454
record count:                 0

---- SQL #8                  
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  /*  csv row 5 out of 6  */ insert into valid_dates values('1886/01/28', 'Automobile')...
sql submitted:                2020-06-30 15:49:34.296452
sql completed:                2020-06-30 15:49:36.703118
record count:                 0

---- SQL #9                  
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  /*  csv row 6 out of 6  */ insert into valid_dates values('1776/07/04', 'USA')...
sql submitted:                2020-06-30 15:49:36.720146
sql completed:                2020-06-30 15:49:39.063358
record count:                 0

---- SQL #10                 
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  /* second method to load .csv into database tables: temp    which opens a .csv file and simply l...
sql submitted:                2020-06-30 15:49:39.079315
sql completed:                2020-06-30 15:49:42.777821
record count:                 0

---- SQL #11                 
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  CREATE MULTISET VOLATILE TABLE "dates.csv" ("cal_date"                    VARCHAR(110)  CHARACTER...
sql submitted:                2020-06-30 15:49:42.794834
sql completed:                2020-06-30 15:49:45.346685
record count:                 0

---- SQL #12                 
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  INSERT INTO "dates.csv" SELECT   cast('2020/01/01' as varchar(110))  ,cast('Decade' as varchar(112...
sql submitted:                2020-06-30 15:49:45.362719
sql completed:                2020-06-30 15:49:47.764325
record count:                 0

---- SQL #13                 
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  /* above volatile table create script for dates.csv */ delete from valid_dates...
sql submitted:                2020-06-30 15:49:47.781857
sql completed:                2020-06-30 15:49:50.163260
record count:                 0

---- SQL #14                 
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  insert into valid_dates Select cal_date, item from "dates.csv"...
sql submitted:                2020-06-30 15:49:50.178308
sql completed:                2020-06-30 15:49:52.578794
record count:                 0

---- SQL #15                 
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  /* birthday is substituted from either the config.yaml,    or (as a default) from fileset.yaml */...
sql submitted:                2020-06-30 15:49:52.595788
sql completed:                2020-06-30 15:49:55.006276
record count:                 0

---- SQL #16                 
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  insert into valid_dates values( cast('1974-12-17' as date), 'Me' )...
sql submitted:                2020-06-30 15:49:55.023268
sql completed:                2020-06-30 15:49:57.423140
record count:                 0

---- SQL #17                 
  parsing for special sql commands
   special command found:     save = birthday.csv
   save found in keys_to_skip, skipping...
connection type:              sqlalchemy
sql, first 100 characters:
  /* export birthday for value:replacement later */  Select top 1 cal_date from valid_dates where it...
sql submitted:                2020-06-30 15:49:57.450084
sql completed:                2020-06-30 15:49:59.935384
record count:                 1
CSV save location:            C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source\demo\birthday.csv
saving file...                
file saved!                   

---- SQL #18                 
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  /* BEGIN file insert: today.sql */  insert into valid_dates values( Current_Date, 'today')...
sql submitted:                2020-06-30 15:50:00.000496
sql completed:                2020-06-30 15:50:02.410323
record count:                 0

---- SQL #19                 
  parsing for special sql commands
connection type:              sqlalchemy
sql, first 100 characters:
  /* simply plop the below sql file right here: */ /* END file insert: today.sql */...
sql submitted:                2020-06-30 15:50:02.429328
sql completed:                2020-06-30 15:50:05.317062
record count:                 0

---- SQL #20                 
  parsing for special sql commands
   special command found:     save = alldates.csv
   save found in keys_to_skip, skipping...
   special command found:     vis = alldates.csv
   vis found in keys_to_skip, skipping...
   special command found:     pptx = AgeReport.pptx
   pptx found in keys_to_skip, skipping...
connection type:              sqlalchemy
sql, first 100 characters:
  /* save the resultset output to the listed .csv */    Select cast(v.cal_date as date) as cal_date...
sql submitted:                2020-06-30 15:50:05.352131
sql completed:                2020-06-30 15:50:07.912444
record count:                 8
CSV save location:            C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source\demo\alldates.csv
saving file...                
file saved!                   

vis cmd:                     found
vis py file:                  C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source\demo\alldates.py
running vis file..            
Vis file complete!            

pptx cmd:                    found
pptx file:                    C:\Users\K******4\PROJECTS\Customer_Success\Github\develop_branch\tdcsm\3_ready_to_run\Transcend_Source\demo\AgeReport.pptx
inserting to pptx file..      
